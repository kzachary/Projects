{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a bipolar random matrix size D*feature_size\n",
    "def genRandomMatrix(D, feature_size):\n",
    "    random_matrix = np.random.rand(D, feature_size)\n",
    "    return np.where(random_matrix>0.5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeMatrix(m):\n",
    "    return np.where(m>0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data by dot multiplying random matrix and inputData\n",
    "# Inputs: inputData(num_trainData*feature_size), random_matrix(D*feature_size)\n",
    "# H(D*1) = random_matrix(D*feature_size) * data.T(feature_size*1)\n",
    "# H.T is a 1*D numpy matrix\n",
    "# return: encoded_data, a list of num_trainData numbers of 1*D numpy matrices\n",
    "def encodeData(inputData, random_matrix):\n",
    "    encoded_data = []\n",
    "    for data in inputData:\n",
    "        H = binarizeMatrix(np.dot(random_matrix, data.T))\n",
    "        encoded_data.append(H.T[0])\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(encoded_data):\n",
    "    train_out = []\n",
    "    for hv in encoded_data:\n",
    "        if len(train_out) == 0:\n",
    "            train_out = hv\n",
    "        else:\n",
    "            train_out += hv\n",
    "    return train_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosAngle(u, v):\n",
    "    return np.dot(u,v)/(LA.norm(u)*LA.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../iot_datasets/danmini/benign.csv\n"
     ]
    }
   ],
   "source": [
    "#Load in the benign dataset\n",
    "inData = []\n",
    "label = 'benign'\n",
    "fileAdr = '../iot_datasets/danmini/' + label + '.csv'\n",
    "print('loading ' + fileAdr)\n",
    "with open(fileAdr) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for buffer in readCSV:\n",
    "        for index, item in enumerate(buffer):\n",
    "            buffer[index] = float(item)\n",
    "\n",
    "        inData.append(buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples for training: 26366\n",
      "samples for testing: 13183\n",
      "feature size: 115\n"
     ]
    }
   ],
   "source": [
    "#set the first 2/3 of benign dataset for training and the last 1/3 for testing\n",
    "btrain = inData[:26366]\n",
    "print('samples for training: ' + str(len(btrain)))\n",
    "btest = inData[26366:]\n",
    "print('samples for testing: ' + str(len(btest)))\n",
    "\n",
    "trainData = np.matrix(btrain)\n",
    "num_trainData, feature_size = trainData.shape\n",
    "print('feature size: ' + str(feature_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode data and add it together to form the final benign class vector used for classification\n",
    "D = 500\n",
    "random_matrix = genRandomMatrix(D, feature_size)\n",
    "encoded_data = encodeData(trainData, random_matrix)\n",
    "\n",
    "benignHV = train(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify the hypervector as either benign or malicious traffic\n",
    "def test(benignHV, test_dict):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for label in test_dict:\n",
    "        for hv in test_dict[label]:\n",
    "            angle = cosAngle(hv, benignHV)\n",
    "            if angle > 0.5 and label == 'benign':\n",
    "                correct += 1\n",
    "            elif angle < 0.5 and label == 'malicious':\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct, total\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../iot_datasets/danmini/ack.csv\n",
      "loading ../iot_datasets/danmini/combo.csv\n",
      "loading ../iot_datasets/danmini/gafScan.csv\n",
      "loading ../iot_datasets/danmini/gafUdp.csv\n",
      "loading ../iot_datasets/danmini/junk.csv\n",
      "loading ../iot_datasets/danmini/scan.csv\n",
      "loading ../iot_datasets/danmini/syn.csv\n",
      "loading ../iot_datasets/danmini/tcp.csv\n",
      "loading ../iot_datasets/danmini/udp.csv\n",
      "loading ../iot_datasets/danmini/udpplain.csv\n"
     ]
    }
   ],
   "source": [
    "#load in the attack datasets, all used for testing\n",
    "attackLabels = ['ack', 'combo', 'gafScan', 'gafUdp', 'junk', 'scan', 'syn', 'tcp', 'udp', 'udpplain']\n",
    "testData = []\n",
    "\n",
    "for label in attackLabels:\n",
    "    fileAdr = '../iot_datasets/danmini/' + label + '.csv'\n",
    "    print('loading ' + fileAdr)\n",
    "    with open(fileAdr) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for buffer in readCSV:\n",
    "            for index, item in enumerate(buffer):\n",
    "                buffer[index] = float(item)\n",
    "\n",
    "            testData.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "testData = np.matrix(testData)\n",
    "btestData = np.matrix(btest)\n",
    "b_encoded_test = encodeData(btestData, random_matrix)\n",
    "encoded_test = encodeData(testData, random_matrix)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "testDict = {}\n",
    "testDict['benign'] = b_encoded_test\n",
    "testDict['malicious'] = encoded_test\n",
    "testlen = len(testDict['benign']) + len(testDict['malicious'])\n",
    "#print(testlen)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.77157300956378\n"
     ]
    }
   ],
   "source": [
    "correct, total = test(benignHV, testDict)\n",
    "accuracy = (correct / total) * 100\n",
    "print(\"accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
